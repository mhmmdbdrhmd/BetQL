# Blackjack Reinforcement Learning App ğŸƒ

![Version](https://img.shields.io/badge/Version-1.0.0-blue.svg)
![Maintained](https://img.shields.io/badge/Maintained%3F-yes-green.svg)
![Made with Python](https://img.shields.io/badge/Made%20with-Python-1f425f.svg)
![Contributions welcome](https://img.shields.io/badge/Contributions-welcome-orange.svg)

## ğŸ“œ Overview
This application leverages reinforcement learning (RL) techniques to train a model to play blackjack. The goal is to demonstrate how an RL agent can learn complex strategies in card games, specifically blackjack, to make intelligent decisions based on the game state.

## ğŸ›  Features

- **Interactive Play Mode**: Users can play blackjack against the trained agent, making decisions in a typical game setup.
- **Training Mode**: Users have the option to train the agent from scratch or continue training from pre-saved models.
- **AI Suggestions**: During interactive play, the application can display suggestions from the trained model, helping users learn effective strategies.
- **Customizable Training**: Users can specify parameters for training, including the number of episodes and the learning rate.

## ğŸ“Š Model Training and Evaluation

### Data Collection
The RL agent learns by playing games against a simulated dealer according to standard blackjack rules. Each game provides the agent with feedback to improve its strategy over time.

### Training the Agent
The agent uses a Q-learning algorithm, a popular method in reinforcement learning, to learn the optimal actions in various game states. This involves updating a Q-table that estimates the rewards for actions taken in particular states.

### Model Evaluation
The agent's performance is evaluated based on its win rate against the dealer over several games. Performance metrics are logged and can be visualized to track the agent's improvement over time.

## ğŸš€ Getting Started

### Installation
Ensure Python 3.8+ is installed. Install dependencies with:

```bash 
pip install -r requirements.txt
```

### Usage
Run the main script to choose between training and playing modes:

```bash
python main.py
```


## ğŸ“ˆ Advanced Usage

- **Load Pre-trained Model**: Users can load a pre-trained model to either continue training or to use in interactive play.
- **Training Options**: The training script accepts command-line arguments to customize the training process, such as the number of training episodes.

## ğŸ”® Future Development

- **Dynamic Model Selection**: Introducing an option for users to build and select their own models, enhancing customization and experimentation.
- **Enhanced Simulation Rules**: Currently, the simulation follows simple blackjack rules. Plans include implementing more specific simulations with detailed rules like European blackjack and other variations.
- **Extended Actions for Bot**: Adding more complex actions such as splitting and doubling down to increase the bot's strategic capabilities.

## ğŸ› Known Issues

- **Saving and Loading**: There are known issues with the save and load functionality that need refinement to ensure reliability and usability.

## ğŸ’– Acknowledgments

- Thanks to all the open-source projects and tools that made this project possible.
- Special thanks to contributors and the Python and machine learning communities for their support and inspiration.
- Thanks to Nicholas Renotte for his informative videos on YouTube, which have provided valuable insights and guidance. [Watch here](https://www.youtube.com/@NicholasRenotte)

## ğŸ¤ Contributing

Contributions to the project are welcome. Please refer to the contributing guidelines for more details on how to submit pull requests, report bugs, or suggest enhancements.

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.


##
  <br>     
  
  </div>
  </div>

 <br><br>

<div align="center">
<div align="center"><p align="center">
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a href="mhmmdbdrhmd@gmail.com" style="text-decoration: none;" alt="Email">
        <img src="https://github.com/mhmmdbdrhmd/Data/blob/main/Icons/ICON%20_Black%20-%20GMail.png" width="6%" />
    </a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a href="https://github.com/mhmmdbdrhmd" style="text-decoration: none;" alt="GitHub">
        <img src="https://github.com/mhmmdbdrhmd/Data/blob/main/Icons/ICON%20_Black-%20Github.png" width="6%" />
    </a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a href="https://www.linkedin.com/in/mohamad-badri-ahmadi-aa2a1a8a?original_referer=https%3A%2F%2Fwww.google.com%2F" style="text-decoration: none;" alt="LinkedIn">
        <img src="https://github.com/mhmmdbdrhmd/Data/blob/main/Icons/ICON%20_Black%20-%20Linkding.png" width="6%" />
    </a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
  <a href="https://twitter.com/mhmmdbdrhmd" style="text-decoration: none;" alt="Twitter">
        <img src="https://github.com/mhmmdbdrhmd/Data/blob/main/Icons/ICON%20_Black%20-%20Twitter%20X.png" width="6%"/>
    </a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</div>
</div>